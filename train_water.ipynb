{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from models.GANF import GANF\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha_init=0.0, batch_norm=False, batch_size=512, cuda=True, data_dir='./data/SWaT_Dataset_Attack_v0.csv', graph='None', h_tol=0.0001, hidden_size=32, lambda1=0.0, log_interval=5, lr=0.002, max_iter=20, model='None', n_blocks=1, n_components=1, n_epochs=1, n_hidden=1, name='GANF_Water', output_dir='./checkpoint/model', rho_init=1.0, rho_max=1e+16, seed=18, weight_decay=0.0005)\n"
     ]
    }
   ],
   "source": [
    "# from data import fetch_dataloaders\n",
    "parser = argparse.ArgumentParser()\n",
    "# files\n",
    "parser.add_argument('--data_dir', type=str, \n",
    "                    default='./data/SWaT_Dataset_Attack_v0.csv', help='Location of datasets.')\n",
    "parser.add_argument('--output_dir', type=str, \n",
    "                    default='./checkpoint/model')\n",
    "parser.add_argument('--name',default='GANF_Water')\n",
    "# restore\n",
    "parser.add_argument('--graph', type=str, default='None')\n",
    "parser.add_argument('--model', type=str, default='None')\n",
    "parser.add_argument('--seed', type=int, default=18, help='Random seed to use.')\n",
    "# made parameters\n",
    "parser.add_argument('--n_blocks', type=int, default=1, help='Number of blocks to stack in a model (MADE in MAF; Coupling+BN in RealNVP).')\n",
    "parser.add_argument('--n_components', type=int, default=1, help='Number of Gaussian clusters for mixture of gaussians models.')\n",
    "parser.add_argument('--hidden_size', type=int, default=32, help='Hidden layer size for MADE (and each MADE block in an MAF).')\n",
    "parser.add_argument('--n_hidden', type=int, default=1, help='Number of hidden layers in each MADE.')\n",
    "parser.add_argument('--batch_norm', type=bool, default=False)\n",
    "# training params\n",
    "parser.add_argument('--batch_size', type=int, default=512)\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "parser.add_argument('--n_epochs', type=int, default=1)\n",
    "parser.add_argument('--lr', type=float, default=2e-3, help='Learning rate.')\n",
    "parser.add_argument('--log_interval', type=int, default=5, help='How often to show loss statistics and save samples.')\n",
    "\n",
    "parser.add_argument('--h_tol', type=float, default=1e-4)\n",
    "parser.add_argument('--rho_max', type=float, default=1e16)\n",
    "parser.add_argument('--max_iter', type=int, default=20)\n",
    "parser.add_argument('--lambda1', type=float, default=0.0)\n",
    "parser.add_argument('--rho_init', type=float, default=1.0)\n",
    "parser.add_argument('--alpha_init', type=float, default=0.0)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "args.cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/zengzihui/ISST/GANF/dataset.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.label[data.label!=\"Normal\"]=1\n",
      "/root/zengzihui/ISST/GANF/dataset.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.label[data.label==\"Normal\"]=0\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset\")\n",
    "from dataset import load_water\n",
    "\n",
    "train_loader, val_loader, test_loader, n_sensor = load_water(args.data_dir, \\\n",
    "                                                                args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73518/725152837.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(init, requires_grad=True, device=device)\n"
     ]
    }
   ],
   "source": [
    "rho = args.rho_init\n",
    "alpha = args.alpha_init\n",
    "lambda1 = args.lambda1\n",
    "h_A_old = np.inf\n",
    "\n",
    "\n",
    "max_iter = args.max_iter\n",
    "rho_max = args.rho_max\n",
    "h_tol = args.h_tol\n",
    "epoch = 0\n",
    "\n",
    "# initialize A\n",
    "if args.graph != 'None':\n",
    "    init = torch.load(args.graph).to(device).abs()\n",
    "    print(\"Load graph from \"+args.graph)\n",
    "else:\n",
    "    from torch.nn.init import xavier_uniform_\n",
    "    init = torch.zeros([n_sensor, n_sensor])\n",
    "    init = xavier_uniform_(init).abs()\n",
    "    init = init.fill_diagonal_(0.0)\n",
    "    \n",
    "A = torch.tensor(init, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GANF n_blocks:  1 \n",
      "GANF input_size:  1 \n",
      "GANF hidden_size:  32 \n",
      "GANF n_hidden:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"GANF n_blocks: \", args.n_blocks, \n",
    "\"\\nGANF input_size: \", 1, \n",
    "\"\\nGANF hidden_size: \", args.hidden_size, \n",
    "\"\\nGANF n_hidden: \", args.n_hidden)\n",
    "\n",
    "model = GANF(args.n_blocks, 1, args.hidden_size, args.n_hidden, dropout=0.0, batch_norm=args.batch_norm)\n",
    "model = model.to(device)\n",
    "\n",
    "if args.model != 'None':\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "    print('Load model from '+args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GANF(\n",
      "  (rnn): LSTM(1, 32, batch_first=True)\n",
      "  (gcn): GNN(\n",
      "    (lin_n): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (lin_r): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (lin_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  )\n",
      "  (nf): MAF(\n",
      "    (net): FlowSequential(\n",
      "      (0): MADE(\n",
      "        (net_input): MaskedLinear(in_features=1, out_features=32, bias=True, cond_features=32)\n",
      "        (net): Sequential(\n",
      "          (0): Tanh()\n",
      "          (1): MaskedLinear(in_features=32, out_features=32, bias=True)\n",
      "          (2): Tanh()\n",
      "          (3): MaskedLinear(in_features=32, out_features=2, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test phase, epoch1, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch1, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.1008569 -2.4684947 -1.1288885 -2.4324481\n",
      "Epoch: 1, train -log_prob: -0.25, test -log_prob: -2.31, roc_val: 0.8766, roc_test: 0.7705 ,h: 0.16985702514648438\n",
      "rho: 1.0, alpha 0.0, h 0.16985702514648438\n",
      "===========================================\n",
      "test phase, epoch2, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch2, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.5993395 -2.9971874 -1.5791131 -2.9648566\n",
      "Epoch: 2, train -log_prob: -0.82, test -log_prob: -2.82, roc_val: 0.8658, roc_test: 0.7707 ,h: 0.10901641845703125\n",
      "rho: 1.0, alpha 0.16985702514648438, h 0.10901641845703125\n",
      "===========================================\n",
      "test phase, epoch3, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch3, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.4807096 -2.635067 -1.4190766 -2.611052\n",
      "Epoch: 3, train -log_prob: 1.82, test -log_prob: -2.50, roc_val: 0.8850, roc_test: 0.7748 ,h: 0.054370880126953125\n",
      "rho: 10.0, alpha 0.16985702514648438, h 0.054370880126953125\n",
      "===========================================\n",
      "test phase, epoch4, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch4, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.8164483 -3.0727954 -1.8130296 -3.0413713\n",
      "Epoch: 4, train -log_prob: -1.04, test -log_prob: -2.86, roc_val: 0.8267, roc_test: 0.7142 ,h: 0.02399444580078125\n",
      "rho: 10.0, alpha 0.7135658264160156, h 0.02399444580078125\n",
      "===========================================\n",
      "test phase, epoch5, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch5, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.9180131 -3.1595137 -1.9132246 -3.1265926\n",
      "Epoch: 5, train -log_prob: 0.69, test -log_prob: -2.98, roc_val: 0.8618, roc_test: 0.7468 ,h: 0.01102447509765625\n",
      "rho: 10.0, alpha 0.9535102844238281, h 0.01102447509765625\n",
      "===========================================\n",
      "test phase, epoch6, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch6, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.3250676 -2.3033202 -1.3948406 -2.2960622\n",
      "Epoch: 6, train -log_prob: 0.71, test -log_prob: -2.19, roc_val: 0.8057, roc_test: 0.7919 ,h: 0.004680633544921875\n",
      "rho: 10.0, alpha 1.0637550354003906, h 0.004680633544921875\n",
      "===========================================\n",
      "test phase, epoch7, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch7, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-2.4254177 -3.535762 -2.4121356 -3.50305\n",
      "Epoch: 7, train -log_prob: -0.95, test -log_prob: -3.36, roc_val: 0.8565, roc_test: 0.7384 ,h: 0.001861572265625\n",
      "rho: 10.0, alpha 1.1105613708496094, h 0.001861572265625\n",
      "===========================================\n",
      "test phase, epoch8, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch8, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-1.712318 -2.5132356 -1.7368715 -2.517123\n",
      "Epoch: 8, train -log_prob: 3.30, test -log_prob: -2.42, roc_val: 0.8437, roc_test: 0.7812 ,h: 0.000530242919921875\n",
      "rho: 10.0, alpha 1.1291770935058594, h 0.000530242919921875\n",
      "===========================================\n",
      "test phase, epoch9, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch9, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-2.5120432 -3.5771058 -2.3399098 -3.5447383\n",
      "Epoch: 9, train -log_prob: -1.43, test -log_prob: -3.43, roc_val: 0.8574, roc_test: 0.7450 ,h: 0.000743865966796875\n",
      "rho: 10.0, alpha 1.1344795227050781, h 0.000743865966796875\n",
      "===========================================\n",
      "test phase, epoch10, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch10, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-2.0590253 -2.967181 -2.025564 -2.9545395\n",
      "Epoch: 10, train -log_prob: 3.85, test -log_prob: -2.85, roc_val: 0.8717, roc_test: 0.7609 ,h: 0.00012969970703125\n",
      "rho: 100.0, alpha 1.1344795227050781, h 0.00012969970703125\n",
      "===========================================\n",
      "test phase, epoch11, x_idx: 0, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 1, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 2, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 3, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 4, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 5, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 6, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 7, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 8, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 9, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 10, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 11, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 12, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 13, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 14, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 15, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 16, x_shape: torch.Size([512, 44, 60, 1])\n",
      "test phase, epoch11, x_idx: 17, x_shape: torch.Size([283, 44, 60, 1])\n",
      "-2.1876636 -3.1083395 -2.243381 -3.113805\n",
      "Epoch: 11, train -log_prob: -1.19, test -log_prob: -3.01, roc_val: 0.7909, roc_test: 0.7751 ,h: 4.57763671875e-05\n",
      "rho: 100.0, alpha 1.1474494934082031, h 4.57763671875e-05\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_value_\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "save_path = os.path.join(args.output_dir,args.name)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "loss_best = 100\n",
    "\n",
    "for _ in range(max_iter):\n",
    "\n",
    "    while rho < rho_max:\n",
    "        lr = args.lr \n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params':model.parameters(), 'weight_decay':args.weight_decay},\n",
    "            {'params': [A]}], lr=lr, weight_decay=0.0)\n",
    "        \n",
    "        for _ in range(args.n_epochs):\n",
    "\n",
    "            # train iteration\n",
    "            loss_train = []\n",
    "            epoch += 1\n",
    "            model.train()\n",
    "\n",
    "            zihuicnt = 0\n",
    "            for x in train_loader:\n",
    "                # print(f\"train phase, epoch{epoch}, x_idx: {zihuicnt}, x_shape: {x.shape}\")\n",
    "                # zihuicnt = zihuicnt + 1\n",
    "                x = x.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = -model(x,  A)\n",
    "                h = torch.trace(torch.matrix_exp( A* A)) - n_sensor\n",
    "                total_loss = loss + 0.5 * rho * h * h + alpha * h\n",
    "\n",
    "                total_loss.backward() \n",
    "                clip_grad_value_(model.parameters(), 1)\n",
    "                optimizer.step()\n",
    "                loss_train.append(loss.item())\n",
    "                A.data.copy_(torch.clamp(A.data, min=0, max=1))\n",
    "                \n",
    "            \n",
    "            # evaluate iteration\n",
    "            model.eval()\n",
    "            loss_val = []\n",
    "            with torch.no_grad():\n",
    "                for x in val_loader:\n",
    "\n",
    "                    x = x.to(device)\n",
    "                    loss = -model.test(x, A.data).cpu().numpy()\n",
    "                    loss_val.append(loss)\n",
    "            loss_val = np.concatenate(loss_val)\n",
    "\n",
    "            loss_test = []\n",
    "            with torch.no_grad():\n",
    "                for x in test_loader:\n",
    "                    print(f\"test phase, epoch{epoch}, x_idx: {zihuicnt}, x_shape: {x.shape}\")\n",
    "                    zihuicnt = zihuicnt + 1\n",
    "                    x = x.to(device)\n",
    "                    loss = -model.test(x, A.data).cpu().numpy()\n",
    "                    loss_test.append(loss)\n",
    "            loss_test = np.concatenate(loss_test)\n",
    "\n",
    "            print(loss_val.max(), loss_val.min(), loss_test.max(), loss_test.min())\n",
    "\n",
    "            loss_val = np.nan_to_num(loss_val)\n",
    "            loss_test = np.nan_to_num(loss_test)\n",
    "            y_test = np.asarray(test_loader.dataset.label.values,dtype=int)\n",
    "            y_pred = loss_test\n",
    "            roc_val = roc_auc_score(np.asarray(val_loader.dataset.label.values,dtype=int),loss_val)\n",
    "            roc_test = roc_auc_score(np.asarray(test_loader.dataset.label.values,dtype=int),loss_test)\n",
    "            print('Epoch: {}, train -log_prob: {:.2f}, test -log_prob: {:.2f}, roc_val: {:.4f}, roc_test: {:.4f} ,h: {}'\\\n",
    "                    .format(epoch, np.mean(loss_train), np.mean(loss_val), roc_val, roc_test, h.item()))\n",
    "    \n",
    "        print('rho: {}, alpha {}, h {}'.format(rho, alpha, h.item()))\n",
    "        print('===========================================')\n",
    "        torch.save(A.data,os.path.join(save_path, \"graph_{}.pt\".format(epoch)))\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"{}_{}.pt\".format(args.name, epoch)))\n",
    "\n",
    "        del optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if h.item() > 0.5 * h_A_old:\n",
    "            rho *= 10\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    h_A_old = h.item()\n",
    "    alpha += rho*h.item()\n",
    "\n",
    "    if h_A_old <= h_tol or rho >=rho_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.113805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.074225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.029855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.983083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.243381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  8987.000000\n",
       "mean     -3.004086\n",
       "std       0.118665\n",
       "min      -3.113805\n",
       "25%      -3.074225\n",
       "50%      -3.029855\n",
       "75%      -2.983083\n",
       "max      -2.243381"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.864417217671871"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = pd.DataFrame(y_pred).quantile(0.75).values[0] + pd.DataFrame(y_pred).std().values[0]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8987 8987\n",
      "f1_score: 0.21145374449339208 precision: 0.18072289156626506  recall: 0.25477707006369427\n"
     ]
    }
   ],
   "source": [
    "# y_test = np.asarray(test_loader.dataset.label.values,dtype=int)\n",
    "# y_pred = loss_test\n",
    "\n",
    "print(len(y_test), len(y_pred))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# pd.DataFrame(y_pred).hist()\n",
    "threshold = pd.DataFrame(y_pred).quantile(0.75).values[0] + pd.DataFrame(y_pred).std().values[0]\n",
    "y_pred_ = np.zeros(y_pred.shape[0])\n",
    "y_pred_[y_pred >= threshold] = 1\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_)\n",
    "pre = precision_score(y_test, y_pred_)\n",
    "rec = recall_score(y_test, y_pred_)\n",
    "\n",
    "\n",
    "print(f\"f1_score: {f1} precision: {pre}  recall: {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, train -log_prob: 0.62, test -log_prob: -1.57, roc_val: 0.5934, roc_test: 0.5806 ,h: 0.0005645751953125\n",
      "save model 12 epoch\n",
      "Epoch: 13, train -log_prob: -2.01, test -log_prob: -2.05, roc_val: 0.7710, roc_test: 0.7635 ,h: 0.0003509521484375\n",
      "save model 13 epoch\n",
      "Epoch: 14, train -log_prob: -2.06, test -log_prob: -2.67, roc_val: 0.8485, roc_test: 0.7788 ,h: 0.00023651123046875\n",
      "save model 14 epoch\n",
      "Epoch: 15, train -log_prob: -2.10, test -log_prob: -2.38, roc_val: 0.8251, roc_test: 0.7911 ,h: 0.000164031982421875\n",
      "Epoch: 16, train -log_prob: -2.11, test -log_prob: -1.83, roc_val: 0.7827, roc_test: 0.7088 ,h: 0.0001220703125\n",
      "Epoch: 17, train -log_prob: -2.12, test -log_prob: -2.09, roc_val: 0.7766, roc_test: 0.7986 ,h: 0.000102996826171875\n",
      "Epoch: 18, train -log_prob: -2.14, test -log_prob: -2.71, roc_val: 0.8249, roc_test: 0.7697 ,h: 8.392333984375e-05\n",
      "save model 18 epoch\n",
      "Epoch: 19, train -log_prob: -2.16, test -log_prob: -2.42, roc_val: 0.8301, roc_test: 0.7568 ,h: 7.2479248046875e-05\n",
      "Epoch: 20, train -log_prob: -2.17, test -log_prob: -1.89, roc_val: 0.7630, roc_test: 0.7891 ,h: 6.866455078125e-05\n",
      "Epoch: 21, train -log_prob: -2.18, test -log_prob: -2.14, roc_val: 0.7613, roc_test: 0.6970 ,h: 5.7220458984375e-05\n",
      "Epoch: 22, train -log_prob: -2.19, test -log_prob: -2.76, roc_val: 0.8352, roc_test: 0.7728 ,h: 5.340576171875e-05\n",
      "save model 22 epoch\n",
      "Epoch: 23, train -log_prob: -2.21, test -log_prob: -2.49, roc_val: 0.8026, roc_test: 0.7712 ,h: 4.9591064453125e-05\n",
      "Epoch: 24, train -log_prob: -2.22, test -log_prob: -1.93, roc_val: 0.7528, roc_test: 0.6648 ,h: 4.57763671875e-05\n",
      "Epoch: 25, train -log_prob: -2.22, test -log_prob: -2.18, roc_val: 0.7828, roc_test: 0.7733 ,h: 4.1961669921875e-05\n",
      "Epoch: 26, train -log_prob: -2.24, test -log_prob: -2.79, roc_val: 0.8234, roc_test: 0.7641 ,h: 4.1961669921875e-05\n",
      "save model 26 epoch\n",
      "Epoch: 27, train -log_prob: -2.26, test -log_prob: -2.51, roc_val: 0.8312, roc_test: 0.7564 ,h: 4.1961669921875e-05\n",
      "Epoch: 28, train -log_prob: -2.26, test -log_prob: -1.97, roc_val: 0.7722, roc_test: 0.7484 ,h: 3.814697265625e-05\n",
      "Epoch: 29, train -log_prob: -2.26, test -log_prob: -2.20, roc_val: 0.8013, roc_test: 0.7498 ,h: 4.57763671875e-05\n",
      "Epoch: 30, train -log_prob: -2.28, test -log_prob: -2.82, roc_val: 0.8391, roc_test: 0.7623 ,h: 4.1961669921875e-05\n",
      "save model 30 epoch\n",
      "Epoch: 31, train -log_prob: -2.29, test -log_prob: -2.53, roc_val: 0.8760, roc_test: 0.7488 ,h: 4.57763671875e-05\n",
      "Epoch: 32, train -log_prob: -2.30, test -log_prob: -1.96, roc_val: 0.9123, roc_test: 0.7351 ,h: 4.57763671875e-05\n",
      "Epoch: 33, train -log_prob: -2.29, test -log_prob: -2.27, roc_val: 0.7181, roc_test: 0.6636 ,h: 4.57763671875e-05\n",
      "Epoch: 34, train -log_prob: -2.30, test -log_prob: -2.82, roc_val: 0.8251, roc_test: 0.7752 ,h: 4.9591064453125e-05\n",
      "Epoch: 35, train -log_prob: -2.33, test -log_prob: -2.52, roc_val: 0.8577, roc_test: 0.7240 ,h: 5.340576171875e-05\n",
      "Epoch: 36, train -log_prob: -2.33, test -log_prob: -2.02, roc_val: 0.8614, roc_test: 0.7343 ,h: 5.340576171875e-05\n",
      "Epoch: 37, train -log_prob: -2.33, test -log_prob: -2.28, roc_val: 0.7379, roc_test: 0.6644 ,h: 6.103515625e-05\n",
      "Epoch: 38, train -log_prob: -2.34, test -log_prob: -2.87, roc_val: 0.7862, roc_test: 0.7498 ,h: 6.866455078125e-05\n",
      "save model 38 epoch\n",
      "Epoch: 39, train -log_prob: -2.35, test -log_prob: -2.59, roc_val: 0.8246, roc_test: 0.7312 ,h: 8.0108642578125e-05\n",
      "Epoch: 40, train -log_prob: -2.36, test -log_prob: -2.10, roc_val: 0.9079, roc_test: 0.7647 ,h: 9.5367431640625e-05\n",
      "Epoch: 41, train -log_prob: -2.36, test -log_prob: -2.32, roc_val: 0.8600, roc_test: 0.7728 ,h: 0.0001068115234375\n"
     ]
    }
   ],
   "source": [
    "lr = args.lr \n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model.parameters(), 'weight_decay':args.weight_decay},\n",
    "    {'params': [A]}], lr=lr, weight_decay=0.0)\n",
    "\n",
    "for _ in range(30):\n",
    "    loss_train = []\n",
    "    epoch += 1\n",
    "    model.train()\n",
    "    for x in train_loader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = -model(x, A)\n",
    "        h = torch.trace(torch.matrix_exp(A*A)) - n_sensor\n",
    "        total_loss = loss + 0.5 * rho * h * h + alpha * h \n",
    "\n",
    "        total_loss.backward()\n",
    "        clip_grad_value_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        loss_train.append(loss.item())\n",
    "        A.data.copy_(torch.clamp(A.data, min=0, max=1))\n",
    "\n",
    "    # eval \n",
    "    model.eval()\n",
    "    loss_val = []\n",
    "    with torch.no_grad():\n",
    "        for x in val_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            loss = -model.test(x, A.data).cpu().numpy()\n",
    "            loss_val.append(loss)\n",
    "    loss_val = np.concatenate(loss_val)\n",
    "\n",
    "    loss_test = []\n",
    "    with torch.no_grad():\n",
    "        for x in test_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            loss = -model.test(x, A.data).cpu().numpy()\n",
    "            loss_test.append(loss)\n",
    "    loss_test = np.concatenate(loss_test)\n",
    "\n",
    "    loss_val = np.nan_to_num(loss_val)\n",
    "    loss_test = np.nan_to_num(loss_test)\n",
    "    y_test = np.asarray(val_loader.dataset.label.values, dtype=int)\n",
    "    y_pred = loss_test\n",
    "    roc_val = roc_auc_score(np.asarray(val_loader.dataset.label.values,dtype=int),loss_val)\n",
    "    roc_test = roc_auc_score(np.asarray(test_loader.dataset.label.values,dtype=int),loss_test)\n",
    "    print('Epoch: {}, train -log_prob: {:.2f}, test -log_prob: {:.2f}, roc_val: {:.4f}, roc_test: {:.4f} ,h: {}'\\\n",
    "            .format(epoch, np.mean(loss_train), np.mean(loss_val), roc_val, roc_test, h.item()))\n",
    "\n",
    "    if np.mean(loss_val) < loss_best:\n",
    "        loss_best = np.mean(loss_val)\n",
    "        print(\"save model {} epoch\".format(epoch))\n",
    "        torch.save(A.data,os.path.join(save_path, \"graph_best.pt\"))\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"{}_best.pt\".format(args.name)))\n",
    "\n",
    "    if epoch % args.log_interval==0:\n",
    "        torch.save(A.data,os.path.join(save_path, \"graph_{}.pt\".format(epoch)))\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, \"{}_{}.pt\".format(args.name, epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.052039381153305204 precision: 0.026724449259660527  recall: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "threshold = pd.DataFrame(y_pred).quantile(0.75).values[0] + pd.DataFrame(y_pred).std().values[0]\n",
    "y_pred_ = np.zeros(y_pred.shape[0])\n",
    "y_pred_[y_pred <= threshold] = 1\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_)\n",
    "pre = precision_score(y_test, y_pred_)\n",
    "rec = recall_score(y_test, y_pred_)\n",
    "\n",
    "\n",
    "print(f\"f1_score: {f1} precision: {pre}  recall: {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8824dd4f119a5db9535273eb75495099f17158e2db07c34482697c6e84d4f6f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('usad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
